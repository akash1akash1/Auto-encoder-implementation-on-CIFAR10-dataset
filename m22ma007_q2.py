# -*- coding: utf-8 -*-
"""M22MA007_Q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Rl70rFDSngS6AauSFYbBZjtnGeYMoX2R
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

transform = transforms.Compose([
    transforms.RandomRotation(degrees=10), #10 means maximum roration angle by which image can be rotated (data augmentation technique)
    transforms.ToTensor(), # converts pixel values from  0-255 to 0-1 and converts numpy to tensors 
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), #these are the mean and sd values of 3 colours
])

class GaussianNoise(object):
    def __init__(self, mean=0., std=1.):
        self.mean = mean
        self.std = std

    def __call__(self, tensor):
        return tensor + torch.randn(tensor.size()) * self.std + self.mean

    def __repr__(self):
        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)

transform.transforms.append(GaussianNoise(mean=0, std=0.1))



transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])



train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)



#seperating specific train taget labels from the cifar10 dataset
target_classes = [1, 3, 5, 7, 9]
train_data = []
train_targets = []
for i, target in enumerate(train_dataset.targets):
    if target in target_classes:
        train_targets.append(target)
        train_data.append(train_dataset.data[i])
train_dataset.targets = train_targets #now our train_dataset  has only the labels with target classes these labels are stored as targets
train_dataset.data = train_data #now our train_dataset has only the images with target classes


#seperating specific test taget labels from the cifar10 dataset
test_data = []
test_targets = []
for i, target in enumerate(test_dataset.targets):
    if target in target_classes:
        test_targets.append(target)
        test_data.append(test_dataset.data[i])
test_dataset.targets = test_targets
test_dataset.data = test_data



# Create data loaders
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)

for i in range(10):   #checking if our dataset labels are only 1,3,5,7,9
    print(train_dataset[i][1])

import matplotlib.pyplot as plt

# Define a dictionary to map class labels to names
label_names = {
    0: 'airplane',
    1: 'automobile',
    2: 'bird',
    3: 'cat',
    4: 'deer',
    5: 'dog',
    6: 'frog',
    7: 'horse',
    8: 'ship',
    9: 'truck'
}

# Visualize some images from the train dataset
fig, ax = plt.subplots(2, 5, figsize=(12, 6))
for i in range(10):
    img, label = train_dataset[i]
    img = img.permute(1, 2, 0)  # Transpose the tensor to (H, W, C)
    ax[i//5, i%5].imshow(img)
    ax[i//5, i%5].set_title(label_names[label])
    ax[i//5, i%5].axis('off')
plt.show()

# Visualize some images from the test dataset
fig, ax = plt.subplots(2, 5, figsize=(12, 6))
for i in range(10):
    img, label = test_dataset[i]
    img = img.permute(1, 2, 0)  # Transpose the tensor to (H, W, C)
    ax[i//5, i%5].imshow(img)
    ax[i//5, i%5].set_title(label_names[label])
    ax[i//5, i%5].axis('off')
plt.show()

# Check if the dataset is normalized
for i, (images, labels) in enumerate(train_dataset):
    if i == 0:
        print('Mean:', images.mean())
        print('Std:', images.std())
        break

def weights_init(m):
    classname = m.__class__.__name__        #He initialization weights are initialized using normal distribution with mean 0 and variance 2/n 
    if classname.find('Conv') != -1:
        torch.nn.init.kaiming_normal_(m.weight.data)
    elif classname.find('Linear') != -1:
        torch.nn.init.kaiming_normal_(m.weight.data)
# import numpy as np
# def weights_init(m):
#     classname = m.__class__.__name__
#     if classname.find('Conv') != -1:
#         torch.nn.init.normal_(m.weight.data, mean=0.0, std=np.sqrt(2.0/m.weight.data.shape[1]))
#     elif classname.find('Linear') != -1:
#         torch.nn.init.normal_(m.weight.data, mean=0.0, std=np.sqrt(2.0/m.weight.data.shape[1]))

# torch.manual_seed(0)  # set the seed for the random number generator

class AutoencoderClassifier(nn.Module):
    def __init__(self):
        super(AutoencoderClassifier, self).__init__()
        
        # Encoder layers
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 12, kernel_size=3, padding=1),  # 3 input channels and 12 output channels [100,12,32,32]
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),        #shape [100,12,16,16] 
            nn.Conv2d(12, 24, kernel_size=3, padding=1),   #shape [100,24,16,16]
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),           #shape [100,24,8,8]
            nn.Conv2d(24, 48, kernel_size=3, padding=1),   #shape [100,48,8,8]
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)        #shape [100,48,4,4]
        )
        
        # Decoder layers
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(48, 24, kernel_size=3, stride=2, padding=1, output_padding=1), # #48 input channels and 24 output channels ..output shape [100,24,8,8]
            nn.ReLU(),
            nn.ConvTranspose2d(24, 12, kernel_size=3, stride=2, padding=1, output_padding=1),  # output shape [100,12,16,16]............ (2*8 -1)+1
            nn.ReLU(),
            nn.ConvTranspose2d(12, 3, kernel_size=3, stride=2, padding=1, output_padding=1),   # output shape [100,12,32,32]
            nn.Tanh()
        )
        
        # Classification layer
        self.classifier = nn.Linear(48, 256)
        
    def forward(self, x):
        # Encode
        encoded = self.encoder(x)
        
        # Decode
        decoded = self.decoder(encoded)
        
        # Classify
        flattened = encoded.view(-1, 48)
        classified = self.classifier(flattened)
        
        return decoded, classified

print(len(train_loader))

model = AutoencoderClassifier()    #calling out model
model.apply(weights_init)          #intializing weights 
recon_loss = nn.MSELoss()           # since they are basically same images in the input and output we use MSE loss
class_loss = nn.CrossEntropyLoss()  #to find classification error at the end 
optimizer = torch.optim.Adam(model.parameters())  #udpades weights 
total_step = len(train_loader)             #number of batched in the data loader

classification_loss_weight =0.1



num_epochs = 10               #loop for number of epochs
# Training loop
for epoch in range(num_epochs):
                          
    for i, (images, labels) in enumerate(train_loader):    #here labels is a tensor of shape batch size
        # Forward pass
        outputs = model(images)                            #we are inputing images inside the model
        recon_outputs, class_outputs = outputs      #recon outputs contain the reconstructed images and class output contain predicted labels for input images
        
        # Calculate the reconstruction loss
        loss_recon = recon_loss(recon_outputs, images)  #comparing recontructed images with original images and cal losss
        
        # # Calculate the classification loss
        # class_labels = labels // 2  # Map target labels to {0, 1, 2, 3, 4}
        # loss_class = class_loss(class_outputs, class_labels)


        # Inside the training loop
        class_labels = torch.tensor([label for label in labels if label in [1, 3, 5, 7, 9]])  #This selects only the labels that are in the set {1, 3, 5, 7, 9}.
        class_outputs_filtered = class_outputs.index_select(0, torch.where(class_labels >= 0)[0])  #selects predicted class probabilities
        class_labels_filtered = class_labels.index_select(0, torch.where(class_labels >= 0)[0]) #selects only the selected labels
        loss_class = class_loss(class_outputs_filtered, class_labels_filtered)  #compares predicted class probabilties to selected labels 


        
        # Combine the losses
        loss = loss_recon + classification_loss_weight * loss_class

        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
         #to avoid printing too many results divide by 100 
        if (i+1) % 100 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Reconstruction Loss: {:.4f}, Classification Loss: {:.4f},Total loss :{:.4f}'
                   .format(epoch+1, num_epochs, i+1, total_step, loss_recon.item(), loss_class.item(), loss.item()))


print("*********************************Training complete!************************************************************************")

# Validation loop
with torch.no_grad():
    total_recon_loss = 0
    total_class_loss = 0
    total_recon_acc = 0
    total_class_acc = 0
    total_samples = 0
    for images, labels in test_loader:
        # Forward pass
        outputs = model(images)
        recon_outputs, class_outputs = outputs
        
        # Calculate reconstruction loss and accuracy
        recon_loss_val = recon_loss(recon_outputs, images)
        total_recon_loss += recon_loss_val.item()
        recon_acc_val = (torch.sum(torch.abs(recon_outputs - images)) / torch.numel(images)).item()
        total_recon_acc += recon_acc_val
        
        # Calculate classification loss and accuracy
        class_indices = [i for i in range(len(labels)) if labels[i] in [1, 3, 5, 7, 9]]
        if len(class_indices) > 0:
            class_outputs_filtered = torch.index_select(class_outputs, 0, torch.tensor(class_indices))
            class_labels_filtered = torch.tensor([label % 2 for label in torch.index_select(labels, 0, torch.tensor(class_indices))])
            class_loss_val = class_loss(class_outputs_filtered, class_labels_filtered)
            total_class_loss += class_loss_val.item()
            _, class_preds = torch.max(class_outputs_filtered, 1)
            class_acc_val = (torch.sum(class_preds == class_labels_filtered) / len(class_indices)).item()
            total_class_acc += class_acc_val
            total_samples += len(class_indices)
    
    # Calculate average losses and accuracies
    avg_recon_loss = total_recon_loss / len(test_loader)
    avg_class_loss = total_class_loss / total_samples
    avg_recon_acc = total_recon_acc / len(test_loader)
    avg_class_acc = total_class_acc / total_samples
    

    print('Validation Results - Reconstruction Loss: {:.4f}, Classification Loss: {:.4f}, Reconstruction Accuracy: {:.4f}, Classification Accuracy: {:.4f}'
         .format(avg_recon_loss, avg_class_loss, avg_recon_acc, avg_class_acc))

import matplotlib.pyplot as plt

# Test the model
model.eval()
with torch.no_grad():
    for images, labels in test_loader:
        outputs = model(images)
        recon_outputs, class_outputs = outputs
        break

# Plot the original images and their reconstructed versions
fig, axs = plt.subplots(2, 5, figsize=(15, 6))
for i in range(5):
    axs[0, i].imshow(images[i].permute(1, 2, 0).numpy())
    axs[1, i].imshow(recon_outputs[i].permute(1, 2, 0).numpy())
    axs[0, i].axis('off')
    axs[1, i].axis('off')

# Print the corresponding labels
print('Labels:', [label.item() for label in labels[:5]])

# model = AutoencoderClassifier()    #calling out model
# model.apply(weights_init)          #intializing weights 
# recon_loss = nn.MSELoss()           # since they are basically same images in the input and output we use MSE loss
# class_loss = nn.CrossEntropyLoss()  #to find classification error at the end 
# optimizer = torch.optim.Adam(model.parameters())  #udpades weights 
# total_step = len(train_loader)             #number of batched in the data loader

# num_epochs = 10               #loop for number of epochs
# # Training loop
# epoch = 0
# while epoch < num_epochs:

#   ####
#   # your code here
#   # epoch += 1  
#   # i = 0
#   # data_iterator = iter(train_loader)
#   # while i < len(train_loader): 
#   #####
#   for i, (images, labels) in enumerate(train_loader): #here labels is a tensor of shape batch size
#     # Forward pass
#     outputs = model(images)                            #we are inputing images inside the model
#     recon_outputs, class_outputs = outputs      #recon outputs contain the reconstructed images and class output contain predicted labels for input images
      
#     # Calculate the reconstruction loss
#     loss_recon = recon_loss(recon_outputs, images)  #comparing recontructed images with original images and cal losss
      
#     # # Calculate the classification loss
#     # class_labels = labels // 2  # Map target labels to {0, 1, 2, 3, 4}
#     # loss_class = class_loss(class_outputs, class_labels)


#     # Inside the training loop
#     class_labels = torch.tensor([label for label in labels if label in [1, 3, 5, 7, 9]])  #This selects only the labels that are in the set {1, 3, 5, 7, 9}.
#     class_outputs_filtered = class_outputs.index_select(0, torch.where(class_labels >= 0)[0])  #selects predicted class probabilities
#     class_labels_filtered = class_labels.index_select(0, torch.where(class_labels >= 0)[0]) #selects only the selected labels
#     loss_class = class_loss(class_outputs_filtered, class_labels_filtered)  #compares predicted class probabilties to selected labels 


      
#     # Combine the losses
#     loss = loss_recon + 0.1 * loss_class

#     # Backward and optimize
#     optimizer.zero_grad()
#     loss.backward()
#     optimizer.step()
#       #to avoid printing too many results divide by 100 
#     if (i+1) % 100 == 0:
#         print ('Epoch [{}/{}], Step [{}/{}], Reconstruction Loss: {:.4f}, Classification Loss: {:.4f},Total loss :{:.4f}'
#                 .format(epoch +1, num_epochs, i+1, total_step, loss_recon.item(), loss_class.item(), loss.item()))
#   epoch += 1
# print("*********************************Training complete!************************************************************************")

# # Define the loss function and optimizer
# # Initialize the model and optimizer
# model = AutoencoderClassifier()
# # model.apply(weights_init)
# # optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
# recon_loss = nn.MSELoss()
# class_loss = nn.CrossEntropyLoss()
# optimizer = torch.optim.Adam(model.parameters())
# total_step = len(train_loader)

    # num_epochs = 5
    # # Training loop
    # for epoch in range(num_epochs):
    #     for i, (images, labels) in enumerate(train_loader):
    #         # Forward pass
    #         outputs = model(images)
    #         recon_outputs, class_outputs = outputs
      
    #         # Calculate the reconstruction loss
    #         loss_recon = recon_loss(recon_outputs, images)
      
    #         # Calculate the classification loss
    #         # class_indices = [i for i in range(len(labels)) if labels[i] in [1, 3, 5, 7, 9]]
    #         class_indices = [1, 3, 5, 7, 9]
    #         if len(class_indices) > 0:
    #             class_outputs_filtered = torch.index_select(class_outputs, 0, torch.tensor(class_indices))
    #             # class_labels_filtered = torch.tensor([label % 2 for label in torch.index_select(labels, 0, torch.tensor(class_indices))])
    #             class_labels_filtered = torch.tensor([1 if label in [1,3,5,7,9] else 0 for label in torch.index_select(labels, 0, torch.tensor(class_indices))])
    #             loss_class = class_loss(class_outputs_filtered, class_labels_filtered)
    #         else:
    #             loss_class = 0
      
    #         # Combine the losses
    #         loss = loss_recon + 0.1 * loss_class

    #         # Backward and optimize
    #         optimizer.zero_grad()
    #         loss.backward()
    #         optimizer.step()

    #         if (i+1) % 100 == 0:
    #             print ('Epoch [{}/{}], Step [{}/{}], Reconstruction Loss: {:.4f}, Classification Loss: {:.4f}'
    #                    .format(epoch+1, num_epochs, i+1, total_step, loss_recon.item(), loss_class.item()))

    # print("Training complete!")

# # Define the autoencoder model
# class Autoencoder(nn.Module):
#     def __init__(self):
#         super(Autoencoder, self).__init__()
#         self.encoder = nn.Sequential(
#             nn.Conv2d(3, 12, kernel_size=3, padding=1),  # 1 input channel and 12 output channels  [100,12,32,32]
#             nn.ReLU(),
#             nn.MaxPool2d(kernel_size=2, stride=2),  #shape [100,12,16,16] 
#             nn.Conv2d(12, 24, kernel_size=3, padding=1), #shape [100,24,16,16]
#             nn.ReLU(),
#             nn.MaxPool2d(kernel_size=2, stride=2), #shape [100,24,8,8]
#             nn.Conv2d(24, 48, kernel_size=3, padding=1), #shape [100,48,8,8]
#             nn.ReLU(),
#             nn.MaxPool2d(kernel_size=2, stride=2)  #shape [100,48,4,4]
#         )
#         self.decoder = nn.Sequential(
#             nn.ConvTranspose2d(48, 24, kernel_size=3, stride=2, padding=1, output_padding=1), #48 input channels and 24 output channels ..output shape [100,24,8,8]
#             #output padding is used so that we will get same size as above 
#             nn.ReLU(),
#             nn.ConvTranspose2d(24, 12, kernel_size=3, stride=2, padding=1, output_padding=1), # output shape [100,12,16,16]............ (2*8 -1)+1
#             nn.ReLU(),
#             nn.ConvTranspose2d(12, 3, kernel_size=3, stride=2, padding=1, output_padding=1), # output shape [100,12,32,32]
#             nn.Tanh()
#         )
        
#     # def forward(self, x):
#     #     x = self.encoder(x)
#     #     x = self.decoder(x)
#     #     return x

#         # Classification layer
#         self.classifier = nn.Linear(48, 256)
        
#     def forward(self, x):
#         # Encode
#         encoded = self.encoder(x)
        
#         # Decode
#         decoded = self.decoder(encoded)
        
#         # Classify
#         flattened = encoded.view(-1, 48)
#         classified = self.classifier(flattened)
        
#         return decoded, classified